# Hadoop-Commands

More_commands: https://data-flair.training/blogs/top-hadoop-hdfs-commands-tutorial/


1. fsck
HDFS Command to check the health of the Hadoop file system.

Command: hdfs fsck /

2.ls
HDFS Command to display the list of Files and Directories in HDFS.

Command: hdfs dfs –ls /

3.mkdir
HDFS Command to create the directory in HDFS.

Usage: hdfs dfs –mkdir /directory_name

Command: hdfs dfs –mkdir /new_staging

4.touchz
HDFS Command to create a file in HDFS with file size 0 bytes.

Usage: hdfs dfs –touchz /directory/filename

Command: hdfs dfs –touchz /new_edureka/sample

5.du
HDFS Command to check the file size. 

Usage: hdfs dfs –du –s /directory/filename

Command: hdfs dfs –du –s /new_edureka/sample

6. cat
HDFS Command that reads a file on HDFS and prints the content of that file to the standard output.

Usage: hdfs dfs –cat /path/to/file_in_hdfs

Command: hdfs dfs –cat /new_edureka/test

7.text
HDFS Command that takes a source file and outputs the file in text format.

Usage: hdfs dfs –text /directory/filename

Command: hdfs dfs –text  /new_edureka/test

8. copyFromLocal
HDFS Command to copy the file from a Local file system to HDFS.

Usage: hdfs dfs -copyFromLocal <localsrc> <hdfs destination> 

Command: hdfs dfs –copyFromLocal /home/edureka/test /new_edureka

9. copyToLocal
HDFS Command to copy the file from HDFS to Local File System.

Usage: hdfs dfs -copyToLocal <hdfs source> <localdst>

Command: hdfs dfs –copyToLocal /new_edureka/test /home/edureka

10. put
HDFS Command to copy single source or multiple sources from local file system to the destination file system.

Usage: hdfs dfs -put <localsrc> <destination>

Command: hdfs dfs –put /home/edureka/test /user

11. get
HDFS Command to copy files from hdfs to the local file system.

Usage: hdfs dfs -get <src> <localdst>

Command: hdfs dfs –get /user/test /home/edureka

12. count
HDFS Command to count the number of directories, files, and bytes under the paths that match the specified file pattern.

Usage: hdfs dfs -count <path>

Command: hdfs dfs –count /user

13. rm
HDFS Command to remove the file from HDFS.

Usage: hdfs dfs –rm <path>     

Command:  hdfs dfs –rm /new_edureka/test

14. rm -r
HDFS Command to remove the entire directory and all of its content from HDFS.

Usage: hdfs dfs -rm -r <path>

Command: hdfs dfs -rm -r  /new_edureka

15. cp
HDFS Command to copy files from source to destination. This command allows multiple sources as well, in which case the destination must be a directory.

Usage: hdfs dfs -cp <src> <dest>

Command: hdfs dfs -cp /user/hadoop/file1 /user/hadoop/file2

Command: hdfs dfs -cp /user/hadoop/file1 /user/hadoop/file2 /user/hadoop/dir  

16. mv
HDFS Command to move files from source to destination. This command allows multiple sources as well, in which case the destination needs to be a directory.

Usage:  hdfs dfs -mv <src> <dest>

Command:  hdfs dfs -mv /user/hadoop/file1 /user/hadoop/file2

17. expunge
HDFS Command that makes the trash empty.

Command: hdfs dfs -expunge

18. rmdir
HDFS Command to remove the directory.

Usage: hdfs dfs -rmdir <path>

Command: hdfs dfs –rmdir /user/hadoop

19. usage
HDFS Command that returns the help for an individual command.

Usage: hdfs dfs -usage <command>

Command: hdfs dfs -usage mkdir

20. help
HDFS Command that displays help for given command or all commands if none is specified.

Command: hdfs dfs -help

How to Configure Replication Factor and Block Size for HDFS?

Hadoop Distributed File System (HDFS) stores files as data blocks and distributes these blocks across the entire cluster. As HDFS was designed to be fault-tolerant and to run on commodity hardware, blocks are replicated a number of times to ensure high data availability. The replication factor is a property that can be set in the HDFS configuration file that will allow you to adjust the global replication factor for the entire cluster. For each block stored in HDFS, there will be n – 1 duplicated blocks distributed across the cluster. For example, if the replication factor was set to 3 (default value in HDFS) there would be one original block and two replicas.


Open the hdfs-site.xml file. This file is usually found in the conf/ folder of the Hadoop installation directory. Change or add the following property to hdfs-site.xml:

<property> 
<name>dfs.replication<name> 
<value>3<value> 
<description>Block Replication<description> 
<property>
  
  hdfs-site.xml is used to configure HDFS. Changing the dfs.replication property in hdfs-site.xml will change the default replication for all files placed in HDFS.

You can also change the replication factor on a per-file basis using the Hadoop FS shell.

[training@localhost ~]$ hadoop fs –setrep –w 3 /my/file

Alternatively, you can change the replication factor of all the files under a directory.

[training@localhost ~]$ hadoop fs –setrep –w 3 -R /my/dir

Hadoop Distributed File System was designed to hold and manage large amounts of data; therefore typical HDFS block sizes are significantly larger than the block sizes you would see for a traditional filesystem (for example, the filesystem on my laptop uses a block size of 4 KB). The block size setting is used by HDFS to divide files into blocks and then distribute those blocks across the cluster. For example, if a cluster is using a block size of 64 MB, and a 128-MB text file was put in to HDFS, HDFS would split the file into two blocks (128 MB/64 MB) and distribute the two chunks to the data nodes in the cluster.

Open the hdfs-site.xml file. This file is usually found in the conf/ folder of the Hadoop installation directory.Set the following property in hdfs-site.xml:

<property> 
<name>dfs.block.size<name> 
<value>134217728<value> 
<description>Block size<description> 
<property>
hdfs-site.xml is used to configure HDFS. Changing the dfs.block.size property in hdfs-site.xml will change the default block size for all the files placed into HDFS. In this case, we set the dfs.block.size to 128 MB. Changing this setting will not affect the block size of any files currently in HDFS. It will only affect the block size of files placed into HDFS after this setting has taken effect.
  

